{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1bkinhnf7AWuPOmCpnVPy64MxX5j2Bu9W",
      "authorship_tag": "ABX9TyMT8ldmNIH7tmdu/dT7KcvE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raulespz/ai_parkinson_detection/blob/main/AI_detect_Parkinson's_Disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkkOetj6WIoi"
      },
      "source": [
        "### ARTIFICIAL INTELIGENCE TO DETECT PARKINSON DESEASE ###\n",
        "\n",
        "## THE THREE MAJOR ASPECTS THAT WE HAVE TO TAKE INTO ACCOUNT IS TO DEVELOP AN AI:\n",
        "\n",
        "      # TRAINING # FOR EXAMPLE WITH from xgboost import XGBClassifier (LIBRARY)\n",
        "      # VALIDATION # from sklearn.metrics import classification_report\n",
        "      # PREDICTION # Using from sklearn.model_selection import train_test_split with model <<< predictions = model.predict(x_test) >>>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt_z1rMAf0oO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7lzSnRDiMKd"
      },
      "source": [
        "# Description: This program detects if an inndividual has Parkinson's disease"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEvvOLtLDzgp"
      },
      "source": [
        "### IMPORT THE LIBRARIES USEFUL TO RUN THE MACHINE LEARNING ###\n",
        "\n",
        "# Get the independencies that I'm going to use trhough this program\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlAfJ88h4iNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "a4099941-36f7-4ef4-fd82-f61ed84f1989"
      },
      "source": [
        "### LOAD THE DATA SET ###\n",
        "from google.colab import drive # Use to load data on Google Colab #\n",
        "df = pd.read_csv('/content/drive/MyDrive/parkinsons.csv')\n",
        "df.head(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>MDVP:Fo(Hz)</th>\n",
              "      <th>MDVP:Fhi(Hz)</th>\n",
              "      <th>MDVP:Flo(Hz)</th>\n",
              "      <th>MDVP:Jitter(%)</th>\n",
              "      <th>MDVP:Jitter(Abs)</th>\n",
              "      <th>MDVP:RAP</th>\n",
              "      <th>MDVP:PPQ</th>\n",
              "      <th>Jitter:DDP</th>\n",
              "      <th>MDVP:Shimmer</th>\n",
              "      <th>MDVP:Shimmer(dB)</th>\n",
              "      <th>Shimmer:APQ3</th>\n",
              "      <th>Shimmer:APQ5</th>\n",
              "      <th>MDVP:APQ</th>\n",
              "      <th>Shimmer:DDA</th>\n",
              "      <th>NHR</th>\n",
              "      <th>HNR</th>\n",
              "      <th>status</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>spread1</th>\n",
              "      <th>spread2</th>\n",
              "      <th>D2</th>\n",
              "      <th>PPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>phon_R01_S01_1</td>\n",
              "      <td>119.992</td>\n",
              "      <td>157.302</td>\n",
              "      <td>74.997</td>\n",
              "      <td>0.00784</td>\n",
              "      <td>0.00007</td>\n",
              "      <td>0.00370</td>\n",
              "      <td>0.00554</td>\n",
              "      <td>0.01109</td>\n",
              "      <td>0.04374</td>\n",
              "      <td>0.426</td>\n",
              "      <td>0.02182</td>\n",
              "      <td>0.03130</td>\n",
              "      <td>0.02971</td>\n",
              "      <td>0.06545</td>\n",
              "      <td>0.02211</td>\n",
              "      <td>21.033</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414783</td>\n",
              "      <td>0.815285</td>\n",
              "      <td>-4.813031</td>\n",
              "      <td>0.266482</td>\n",
              "      <td>2.301442</td>\n",
              "      <td>0.284654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>phon_R01_S01_2</td>\n",
              "      <td>122.400</td>\n",
              "      <td>148.650</td>\n",
              "      <td>113.819</td>\n",
              "      <td>0.00968</td>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.00465</td>\n",
              "      <td>0.00696</td>\n",
              "      <td>0.01394</td>\n",
              "      <td>0.06134</td>\n",
              "      <td>0.626</td>\n",
              "      <td>0.03134</td>\n",
              "      <td>0.04518</td>\n",
              "      <td>0.04368</td>\n",
              "      <td>0.09403</td>\n",
              "      <td>0.01929</td>\n",
              "      <td>19.085</td>\n",
              "      <td>1</td>\n",
              "      <td>0.458359</td>\n",
              "      <td>0.819521</td>\n",
              "      <td>-4.075192</td>\n",
              "      <td>0.335590</td>\n",
              "      <td>2.486855</td>\n",
              "      <td>0.368674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>phon_R01_S01_3</td>\n",
              "      <td>116.682</td>\n",
              "      <td>131.111</td>\n",
              "      <td>111.555</td>\n",
              "      <td>0.01050</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00544</td>\n",
              "      <td>0.00781</td>\n",
              "      <td>0.01633</td>\n",
              "      <td>0.05233</td>\n",
              "      <td>0.482</td>\n",
              "      <td>0.02757</td>\n",
              "      <td>0.03858</td>\n",
              "      <td>0.03590</td>\n",
              "      <td>0.08270</td>\n",
              "      <td>0.01309</td>\n",
              "      <td>20.651</td>\n",
              "      <td>1</td>\n",
              "      <td>0.429895</td>\n",
              "      <td>0.825288</td>\n",
              "      <td>-4.443179</td>\n",
              "      <td>0.311173</td>\n",
              "      <td>2.342259</td>\n",
              "      <td>0.332634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>phon_R01_S01_4</td>\n",
              "      <td>116.676</td>\n",
              "      <td>137.871</td>\n",
              "      <td>111.366</td>\n",
              "      <td>0.00997</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00502</td>\n",
              "      <td>0.00698</td>\n",
              "      <td>0.01505</td>\n",
              "      <td>0.05492</td>\n",
              "      <td>0.517</td>\n",
              "      <td>0.02924</td>\n",
              "      <td>0.04005</td>\n",
              "      <td>0.03772</td>\n",
              "      <td>0.08771</td>\n",
              "      <td>0.01353</td>\n",
              "      <td>20.644</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434969</td>\n",
              "      <td>0.819235</td>\n",
              "      <td>-4.117501</td>\n",
              "      <td>0.334147</td>\n",
              "      <td>2.405554</td>\n",
              "      <td>0.368975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>phon_R01_S01_5</td>\n",
              "      <td>116.014</td>\n",
              "      <td>141.781</td>\n",
              "      <td>110.655</td>\n",
              "      <td>0.01284</td>\n",
              "      <td>0.00011</td>\n",
              "      <td>0.00655</td>\n",
              "      <td>0.00908</td>\n",
              "      <td>0.01966</td>\n",
              "      <td>0.06425</td>\n",
              "      <td>0.584</td>\n",
              "      <td>0.03490</td>\n",
              "      <td>0.04825</td>\n",
              "      <td>0.04465</td>\n",
              "      <td>0.10470</td>\n",
              "      <td>0.01767</td>\n",
              "      <td>19.649</td>\n",
              "      <td>1</td>\n",
              "      <td>0.417356</td>\n",
              "      <td>0.823484</td>\n",
              "      <td>-3.747787</td>\n",
              "      <td>0.234513</td>\n",
              "      <td>2.332180</td>\n",
              "      <td>0.410335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>phon_R01_S22_5</td>\n",
              "      <td>157.447</td>\n",
              "      <td>163.267</td>\n",
              "      <td>149.605</td>\n",
              "      <td>0.00369</td>\n",
              "      <td>0.00002</td>\n",
              "      <td>0.00201</td>\n",
              "      <td>0.00197</td>\n",
              "      <td>0.00602</td>\n",
              "      <td>0.03272</td>\n",
              "      <td>0.283</td>\n",
              "      <td>0.01813</td>\n",
              "      <td>0.01909</td>\n",
              "      <td>0.02571</td>\n",
              "      <td>0.05439</td>\n",
              "      <td>0.01018</td>\n",
              "      <td>21.693</td>\n",
              "      <td>1</td>\n",
              "      <td>0.447285</td>\n",
              "      <td>0.705658</td>\n",
              "      <td>-6.247076</td>\n",
              "      <td>0.180528</td>\n",
              "      <td>2.344348</td>\n",
              "      <td>0.164916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>phon_R01_S22_6</td>\n",
              "      <td>159.116</td>\n",
              "      <td>168.913</td>\n",
              "      <td>144.811</td>\n",
              "      <td>0.00342</td>\n",
              "      <td>0.00002</td>\n",
              "      <td>0.00178</td>\n",
              "      <td>0.00184</td>\n",
              "      <td>0.00535</td>\n",
              "      <td>0.03381</td>\n",
              "      <td>0.307</td>\n",
              "      <td>0.01806</td>\n",
              "      <td>0.02024</td>\n",
              "      <td>0.02809</td>\n",
              "      <td>0.05417</td>\n",
              "      <td>0.00852</td>\n",
              "      <td>22.663</td>\n",
              "      <td>1</td>\n",
              "      <td>0.366329</td>\n",
              "      <td>0.693429</td>\n",
              "      <td>-6.417440</td>\n",
              "      <td>0.194627</td>\n",
              "      <td>2.473239</td>\n",
              "      <td>0.151709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>phon_R01_S24_1</td>\n",
              "      <td>125.036</td>\n",
              "      <td>143.946</td>\n",
              "      <td>116.187</td>\n",
              "      <td>0.01280</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>0.00743</td>\n",
              "      <td>0.00623</td>\n",
              "      <td>0.02228</td>\n",
              "      <td>0.03886</td>\n",
              "      <td>0.342</td>\n",
              "      <td>0.02135</td>\n",
              "      <td>0.02174</td>\n",
              "      <td>0.03088</td>\n",
              "      <td>0.06406</td>\n",
              "      <td>0.08151</td>\n",
              "      <td>15.338</td>\n",
              "      <td>1</td>\n",
              "      <td>0.629574</td>\n",
              "      <td>0.714485</td>\n",
              "      <td>-4.020042</td>\n",
              "      <td>0.265315</td>\n",
              "      <td>2.671825</td>\n",
              "      <td>0.340623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>phon_R01_S24_2</td>\n",
              "      <td>125.791</td>\n",
              "      <td>140.557</td>\n",
              "      <td>96.206</td>\n",
              "      <td>0.01378</td>\n",
              "      <td>0.00011</td>\n",
              "      <td>0.00826</td>\n",
              "      <td>0.00655</td>\n",
              "      <td>0.02478</td>\n",
              "      <td>0.04689</td>\n",
              "      <td>0.422</td>\n",
              "      <td>0.02542</td>\n",
              "      <td>0.02630</td>\n",
              "      <td>0.03908</td>\n",
              "      <td>0.07625</td>\n",
              "      <td>0.10323</td>\n",
              "      <td>15.433</td>\n",
              "      <td>1</td>\n",
              "      <td>0.571010</td>\n",
              "      <td>0.690892</td>\n",
              "      <td>-5.159169</td>\n",
              "      <td>0.202146</td>\n",
              "      <td>2.441612</td>\n",
              "      <td>0.260375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>phon_R01_S24_3</td>\n",
              "      <td>126.512</td>\n",
              "      <td>141.756</td>\n",
              "      <td>99.770</td>\n",
              "      <td>0.01936</td>\n",
              "      <td>0.00015</td>\n",
              "      <td>0.01159</td>\n",
              "      <td>0.00990</td>\n",
              "      <td>0.03476</td>\n",
              "      <td>0.06734</td>\n",
              "      <td>0.659</td>\n",
              "      <td>0.03611</td>\n",
              "      <td>0.03963</td>\n",
              "      <td>0.05783</td>\n",
              "      <td>0.10833</td>\n",
              "      <td>0.16744</td>\n",
              "      <td>12.435</td>\n",
              "      <td>1</td>\n",
              "      <td>0.638545</td>\n",
              "      <td>0.674953</td>\n",
              "      <td>-3.760348</td>\n",
              "      <td>0.242861</td>\n",
              "      <td>2.634633</td>\n",
              "      <td>0.378483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  ...   spread2        D2       PPE\n",
              "0   phon_R01_S01_1      119.992       157.302  ...  0.266482  2.301442  0.284654\n",
              "1   phon_R01_S01_2      122.400       148.650  ...  0.335590  2.486855  0.368674\n",
              "2   phon_R01_S01_3      116.682       131.111  ...  0.311173  2.342259  0.332634\n",
              "3   phon_R01_S01_4      116.676       137.871  ...  0.334147  2.405554  0.368975\n",
              "4   phon_R01_S01_5      116.014       141.781  ...  0.234513  2.332180  0.410335\n",
              "..             ...          ...           ...  ...       ...       ...       ...\n",
              "95  phon_R01_S22_5      157.447       163.267  ...  0.180528  2.344348  0.164916\n",
              "96  phon_R01_S22_6      159.116       168.913  ...  0.194627  2.473239  0.151709\n",
              "97  phon_R01_S24_1      125.036       143.946  ...  0.265315  2.671825  0.340623\n",
              "98  phon_R01_S24_2      125.791       140.557  ...  0.202146  2.441612  0.260375\n",
              "99  phon_R01_S24_3      126.512       141.756  ...  0.242861  2.634633  0.378483\n",
              "\n",
              "[100 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AilabpufNkUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02655bf8-6234-42c0-9f84-dcbc3b6aee2e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaaeS2aPCkkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba43858-a29a-4c41-c7a4-865c8a770307"
      },
      "source": [
        "### CHECK THIS DATA FOR MISSING VALUES ###\n",
        "df.isnull().values.any()\n",
        "# So is false there is not an empty values, there are complete data with full values."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPvWsEhLIocj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40c6fd3-9763-48c4-9d0c-a5bee5c0cb5f"
      },
      "source": [
        "# Get the number of rows and columsn inthe data set\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RiydspyIvyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b0f3e2-e340-4e8e-fce3-6cdee77f5bbe"
      },
      "source": [
        "#Get the count of people that has the desease and people that does not has the desease\n",
        "df['status'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    147\n",
              "0     48\n",
              "Name: status, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YKFx9aPJAfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd84d1e-2317-4350-fec7-d9b858576c7e"
      },
      "source": [
        "#The consecuently values are the results of the run cell before, so check it out.\n",
        "\n",
        "percent_has_disease = 147 / (147+48) * 100\n",
        "percent_dont_have_disease = 48 / (147+48) * 100\n",
        "\n",
        "print('If I guess the individual did not have Parkinson disease, I would be correct', percent_dont_have_disease, '% of the time' )\n",
        "print('If I guess the individual has Parkinson disease, I would be correct', percent_has_disease, '% of the time' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If I guess the individual did not have Parkinson disease, I would be correct 24.615384615384617 % of the time\n",
            "If I guess the individual has Parkinson disease, I would be correct 75.38461538461539 % of the time\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Hy4JucKZdC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "b6e1d692-badb-403f-eb2c-c3447611f192"
      },
      "source": [
        "# So we are getting more accurate the project and not only guessing we have  to be more precisely.\n",
        "\n",
        "#Visualize the count\n",
        "sns.countplot(df['status'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d7e270f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYlSVOKfKtMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b80374-89eb-4b2b-c68d-77722673ea83"
      },
      "source": [
        "#Get the data types\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name                 object\n",
              "MDVP:Fo(Hz)         float64\n",
              "MDVP:Fhi(Hz)        float64\n",
              "MDVP:Flo(Hz)        float64\n",
              "MDVP:Jitter(%)      float64\n",
              "MDVP:Jitter(Abs)    float64\n",
              "MDVP:RAP            float64\n",
              "MDVP:PPQ            float64\n",
              "Jitter:DDP          float64\n",
              "MDVP:Shimmer        float64\n",
              "MDVP:Shimmer(dB)    float64\n",
              "Shimmer:APQ3        float64\n",
              "Shimmer:APQ5        float64\n",
              "MDVP:APQ            float64\n",
              "Shimmer:DDA         float64\n",
              "NHR                 float64\n",
              "HNR                 float64\n",
              "status                int64\n",
              "RPDE                float64\n",
              "DFA                 float64\n",
              "spread1             float64\n",
              "spread2             float64\n",
              "D2                  float64\n",
              "PPE                 float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txMuCq4iK9LB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "66cea1b7-37ab-4540-ec1a-fb00261d01ea"
      },
      "source": [
        "### SEPARATE THE MATRIX 'X' DATA SET AND THE ARRAY 'Y' OUR TARGET ###\n",
        "# Create the feature data set\n",
        "\n",
        "# We are going to erase the variable name becasue not is useful to do the project right now\n",
        "x = df.drop(['name'], 1)\n",
        "x = np.array(x.drop(['status'], 1)) # np.array create an array of all the columns of the table eccept for status that is deleted with x.drop, 'status' column, because this corresponde the variable (y)\n",
        "# x here is taking each row represents an array from each value from 'status' that is the variable that says as the patient has or not Parkinson Disease witht he variable (y).\n",
        "# 10^2 = E+02\n",
        "# For example:\n",
        "# The first array of(x) is: ([[1.199920e+02, 1.573020e+02, 7.499700e+01, ..., 2.664820e-01,\n",
        "#        2.301442e+00, 2.846540e-01].  that is the first row.\n",
        "# The first row of (y) is :  1\n",
        "# Create the target data set\n",
        "\n",
        "y = np.array(df['status']) #Whit the df is going to take only values from the status.\n",
        "\n",
        "display (x)\n",
        "# 10^2 = E+02  to understand the values that are inside the matrix of x matrix.\n",
        "display (y)\n",
        "# y is going to display the numbers 1 or 0 that mean values that has or not the desease and is content in status from the database.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[1.199920e+02, 1.573020e+02, 7.499700e+01, ..., 2.664820e-01,\n",
              "        2.301442e+00, 2.846540e-01],\n",
              "       [1.224000e+02, 1.486500e+02, 1.138190e+02, ..., 3.355900e-01,\n",
              "        2.486855e+00, 3.686740e-01],\n",
              "       [1.166820e+02, 1.311110e+02, 1.115550e+02, ..., 3.111730e-01,\n",
              "        2.342259e+00, 3.326340e-01],\n",
              "       ...,\n",
              "       [1.746880e+02, 2.400050e+02, 7.428700e+01, ..., 1.584530e-01,\n",
              "        2.679772e+00, 1.317280e-01],\n",
              "       [1.987640e+02, 3.969610e+02, 7.490400e+01, ..., 2.074540e-01,\n",
              "        2.138608e+00, 1.233060e-01],\n",
              "       [2.142890e+02, 2.602770e+02, 7.797300e+01, ..., 1.906670e-01,\n",
              "        2.555477e+00, 1.485690e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4JlgXRzLnCg"
      },
      "source": [
        "### TO SEPARATE THE DATA FROM WHAT IS GOING TO BE TRAINED AND TESTED ###\n",
        "\n",
        "## from sklearn.model_selection import train_test_split ##\n",
        "\n",
        "#Split the data to be into 80% training and 20% testing data set\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
        "\n",
        "#print(x_train)\n",
        "#print(x_test)\n",
        "#print(y_train)\n",
        "#print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcAPohEtMDtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95991338-8372-4b52-f8bb-e165f06efaf1"
      },
      "source": [
        "#Transform the data, the feature data values between 0 and 1\n",
        "sc = MinMaxScaler(feature_range=(0,1))  #To understand what do MinMaxScaler uses this formula to create new values from the matrix of x_train or others:\n",
        "#  is this = X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
        "x_train = sc.fit_transform(x_train) #With fit.transform we trasform the data from the feature specified with sc from 0 to 1. #Which one is totally necessary due to the values\n",
        "# of the matrix are upper 100, 150, etc, so this help to have values among 0 to 1, that are more handable amounts.\n",
        "print(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "\n",
        "# Only was transformed x_test and x_train due to the values of y_test and y_train are in 0 or 1 because say to us if the patient has or not the disease."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.41180413 0.12484563 0.05964512 ... 0.44432814 0.31244317 0.26005327]\n",
            " [0.7173698  0.24870531 0.13938305 ... 0.56319068 0.5016638  0.38933326]\n",
            " [0.15260091 0.04993825 0.22233929 ... 0.67475727 0.44307139 0.34101585]\n",
            " ...\n",
            " [0.40612293 0.12490687 0.47065529 ... 0.45221389 0.40998359 0.18553398]\n",
            " [0.64016929 0.23302816 0.57863829 ... 0.74081253 0.82370406 0.77482458]\n",
            " [0.76719202 0.24121988 0.76884636 ... 0.40093738 0.48003219 0.19023545]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxPxwfssMstj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b2c921-607d-4d16-87c4-e8393f8e40aa"
      },
      "source": [
        "### TRAINING DATA ###\n",
        "## How to boost our machine learning, we should enhance it employing the large samples posible to the data training ##\n",
        "\n",
        "#Here we are training the model (((The clf (for classifier) estimator instance is first fitted to the model; that is, it must learn from the model. This is done by passing our training set to the fit method.)))<<<this was extracted from: https://scikit-learn.org/stable/tutorial/basic/tutorial.html>>>\n",
        "#Create the XGBClassifier\n",
        "model = XGBClassifier(Sumax_depth=6, base_score=0.5, booster='gbtree',\n",
        "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
        "              gamma=0.0, learning_rate=0.25, max_delta_step=0, max_depth=3,\n",
        "              min_child_weight=1, missing=None, n_estimators=70, n_jobs=1,\n",
        "              nthread=None, objective='binary:logistic', random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, subsample=0.7, verbosity=1).fit(x_train, y_train);\n",
        "print(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(Sumax_depth=6, base_score=0.5, booster='gbtree',\n",
            "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
            "              gamma=0.0, learning_rate=0.25, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=70, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.7, verbosity=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4cj8eY5NOO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d06bb56-9aed-47b2-95e9-1ffb6bafe685"
      },
      "source": [
        "### ANOTHER METHOD FOR TRAINING THE DATA WITH GRIDSEARCHCV ###\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = XGBClassifier()\n",
        "grid = GridSearchCV(clf, param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')}, n_jobs=-1, scoring=\"roc_auc\", cv=3)\n",
        "\n",
        "grid.fit(x_train, y_train)\n",
        "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.925535 using {'C': 1, 'kernel': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o79lfyhh_QF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc572761-7e0f-4921-e08b-5695f3bff6d4"
      },
      "source": [
        "### PREDICTIONS ###\n",
        "\n",
        "# Get the model predictions\n",
        "predictions = model.predict(x_test)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AG6rsJKiIvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef01f535-65da-49b0-bdce-543993324948"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ymNk-ctNWtz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68991be8-fbe8-46e8-e566-ad9ab977ed57"
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h04MtuKog2Pb"
      },
      "source": [
        "########## UNTIL HERE THE END OF THE CODE DONE BEFORE #######"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MOJRbnmnMm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0e5b44-c5d8-408a-fa61-bd209ddf0863"
      },
      "source": [
        "##### VALIDATION #######\n",
        "\n",
        "#Test model accuracy on test data on confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print(classification_report(y_test, predictions))\n",
        "print(cohen_kappa_score(y_test, predictions))\n",
        "print(accuracy_score(y_test, predictions))\n",
        "print(f1_score(y_test, predictions, average='binary'))\n",
        "print(matthews_corrcoef(y_test, predictions))\n",
        "print(balanced_accuracy_score(y_test, predictions))\n",
        "print(roc_auc_score(y_test, predictions))\n",
        "#  cm = confusion_matrix(y_test, model.predict(x_test)) # show us the true positives, true negatives, FP, FN\n",
        "#  cm\n",
        "\n",
        "#  for i in range(len(cm)):\n",
        "\n",
        "#  TP = cm[0][0]  #[0][0] That tell us the position of the variables e the row 0 a the colum 0 too.\n",
        "#  FP = cm[0][1]\n",
        "#  FN = cm[1][0]\n",
        "#  TN = cm[1][1]\n",
        "\n",
        "#  total = TP+FP+FN+TN\n",
        "\n",
        "#  print(cm)\n",
        "#  print('Testing Accuracy = ', (TP+TN)/(total))\n",
        "#  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 7  1]\n",
            " [ 0 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.93         8\n",
            "           1       0.97      1.00      0.98        31\n",
            "\n",
            "    accuracy                           0.97        39\n",
            "   macro avg       0.98      0.94      0.96        39\n",
            "weighted avg       0.98      0.97      0.97        39\n",
            "\n",
            "0.9175475687103594\n",
            "0.9743589743589743\n",
            "0.9841269841269841\n",
            "0.9206824914160148\n",
            "0.9375\n",
            "0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWNRA2-dz-YE"
      },
      "source": [
        "#### This is another way to choose an specific hyperparameters to us classifier ####\n",
        "\n",
        "#### VIDEO TUTORIAL : https://www.youtube.com/watch?v=9HomdnM12o4\n",
        "\n",
        "params = {\n",
        "    \"learning_rate\"    :  [ 0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ],\n",
        "    \"Su\"\n",
        "    \"max_depth\"        :  [ 3, 4, 5, 6, 8, 10, 12, 15 ],\n",
        "    \"min_child_weight\" :  [ 1, 3, 5, 7, 20, 50, 75, 100],\n",
        "    \"gamma\"            :  [ 0.0, 0.1, 0.2, 0.3, 0.4, 0.5 ],\n",
        "    \"colsample_bytree\" :  [ 0.3, 0.4, 0.5, 0.7],\n",
        "    \"colsample_bylevel\":  [ 0.1, 0.3, 0.5, 0.7, 0.9, 1 ],\n",
        "    \"subsample\"        :  [ 0.1, 0.3, 0.5, 0.7, 0.9, 1 ],\n",
        "    \"reg_lambda\"       :  [ 1, 3, 5, 7],\n",
        "    \"n_estimators\"     :  [ 10, 30, 50, 70, 100]\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z02PC2iR0OJd"
      },
      "source": [
        "#### This is another way to choose an specific hyperparameters to us classifier ####\n",
        "\n",
        "#### VIDEO TUTORIAL : https://www.youtube.com/watch?v=9HomdnM12o4\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_kJcR7A5oQk"
      },
      "source": [
        "#### This is another way to choose an specific hyperparameters to us classifier ####\n",
        "\n",
        "#### VIDEO TUTORIAL : https://www.youtube.com/watch?v=9HomdnM12o4   ###NAME: Hyperparameter Optimization for Xgboost, CHANNEL: Krish Naik\n",
        "\n",
        "\n",
        "classifier=xgboost.XGBClassifier()\n",
        "random_search=RandomizedSearchCV(classifier, param_distributions= params, n_iter=5, scoring='roc_auc', n_jobs=-1, cv=5, verbose=3, refit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPWcpWAq7APs",
        "outputId": "6b8a6706-5162-43b8-b587-3bb4a532a07a"
      },
      "source": [
        "#### This is another way to choose an specific hyperparameters to us classifier ####\n",
        "\n",
        "random_search.fit(x_train, y_train)   ## I had problems with the video tutorial, so this helps = https://datascience.stackexchange.com/questions/71767/randomizedsearchcv-object-has-no-attribute-best-estimator\n",
        "print(random_search.best_estimator_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(Sumax_depth=6, base_score=0.5, booster='gbtree',\n",
            "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
            "              gamma=0.0, learning_rate=0.25, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=70, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.7, verbosity=1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    1.3s remaining:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuNH7fc9_4ev",
        "outputId": "fa01dbab-c74c-4e24-f68e-7934ce3a96af"
      },
      "source": [
        "#### This is another way to choose an specific hyperparameters to us classifier ####\n",
        "\n",
        "print(random_search.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'subsample': 0.7, 'reg_lambda': 1, 'n_estimators': 70, 'min_child_weight': 1, 'learning_rate': 0.25, 'gamma': 0.0, 'colsample_bytree': 0.7, 'colsample_bylevel': 1, 'Sumax_depth': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e9mZCQLDWZp"
      },
      "source": [
        "#### This is another way to choose an specific hyperparameters to us classifier ####\n",
        "\n",
        "classifier = xgboost.XGBClassifier(Sumax_depth=6, base_score=0.5, booster='gbtree',\n",
        "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
        "              gamma=0.0, learning_rate=0.25, max_delta_step=0, max_depth=3,\n",
        "              min_child_weight=1, missing=None, n_estimators=70, n_jobs=1,\n",
        "              nthread=None, objective='binary:logistic', random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, subsample=0.7, verbosity=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DPM-5ldg883",
        "outputId": "2cc346f5-3da8-4af7-f6f8-cf5d6d14af49"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, predictions)\n",
        "\n",
        "#cm = confusion_matrix(y_test, predict(x_test)) # show us the true positives, true negatives, FP, FN\n",
        "\n",
        "\n",
        "  #TP = cm[0][0]  #[0][0] That tell us the position of the variables e the row 0 a the colum 0 too.\n",
        " # FP = cm[0][1]\n",
        "  #FN = cm[1][0]\n",
        "  #TN = cm[1][1]\n",
        "\n",
        " # total = TP+FP+FN+TN\n",
        "\n",
        " # print(cm)\n",
        " # print('Testing Accuracy = ', (TP+TN)/(total))\n",
        " # print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  2],\n",
              "       [ 0, 34]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1aHyE6iHMDb"
      },
      "source": [
        "####\n",
        "#### THIS IS GOING TO BE FOR INTRODUCE A NEW DATA AND PREDICT ####\n",
        "####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "4fR4acX6Gyma",
        "outputId": "6e416426-94fb-4a0f-90a2-689f5f03d3bf"
      },
      "source": [
        "#### THIS IS GOING TO BE FOR INTRODUCE A NEW DATA AND PREDICT ####\n",
        "\n",
        "### LOAD THE DATA SET ###\n",
        "from google.colab import drive # Use to load data on Google Colab #\n",
        "df = pd.read_csv('/content/drive/MyDrive/parkinsonsforpredict.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>MDVP:Fo(Hz)</th>\n",
              "      <th>MDVP:Fhi(Hz)</th>\n",
              "      <th>MDVP:Flo(Hz)</th>\n",
              "      <th>MDVP:Jitter(%)</th>\n",
              "      <th>MDVP:Jitter(Abs)</th>\n",
              "      <th>MDVP:RAP</th>\n",
              "      <th>MDVP:PPQ</th>\n",
              "      <th>Jitter:DDP</th>\n",
              "      <th>MDVP:Shimmer</th>\n",
              "      <th>MDVP:Shimmer(dB)</th>\n",
              "      <th>Shimmer:APQ3</th>\n",
              "      <th>Shimmer:APQ5</th>\n",
              "      <th>MDVP:APQ</th>\n",
              "      <th>Shimmer:DDA</th>\n",
              "      <th>NHR</th>\n",
              "      <th>HNR</th>\n",
              "      <th>status</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>spread1</th>\n",
              "      <th>spread2</th>\n",
              "      <th>D2</th>\n",
              "      <th>PPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>phon_R01_S01_12378678</td>\n",
              "      <td>160.234</td>\n",
              "      <td>290.302</td>\n",
              "      <td>150.997</td>\n",
              "      <td>0.00984</td>\n",
              "      <td>0.00011</td>\n",
              "      <td>0.0137</td>\n",
              "      <td>0.00954</td>\n",
              "      <td>0.06109</td>\n",
              "      <td>0.07374</td>\n",
              "      <td>0.826</td>\n",
              "      <td>0.05182</td>\n",
              "      <td>0.0613</td>\n",
              "      <td>0.04971</td>\n",
              "      <td>0.10545</td>\n",
              "      <td>0.17211</td>\n",
              "      <td>21.033</td>\n",
              "      <td>1</td>\n",
              "      <td>0.714783</td>\n",
              "      <td>0.846385</td>\n",
              "      <td>-6.983031</td>\n",
              "      <td>0.388482</td>\n",
              "      <td>2.709662</td>\n",
              "      <td>0.294524</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    name  MDVP:Fo(Hz)  ...        D2       PPE\n",
              "0  phon_R01_S01_12378678      160.234  ...  2.709662  0.294524\n",
              "\n",
              "[1 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "vEaZk3OdHKES",
        "outputId": "517d1531-0c70-4599-a920-9e615b0089a8"
      },
      "source": [
        "#### THIS IS GOING TO BE FOR INTRODUCE A NEW DATA AND PREDICT ####\n",
        "\n",
        "xprobe = df.drop(['name'], 1) ## predictprobe this is going to be the 'x' here!, so predictprobe = x\n",
        "xprobe = np.array(xprobe.drop(['status'], 1)) # np.array create an array of all the columns of the table eccept for status that is deleted with x.drop, 'status' column, because this corresponde the variable (y)\n",
        "# x here is taking each row represents an array from each value from 'status' that is the variable that says as the patient has or not Parkinson Disease witht he variable (y).\n",
        "# 10^2 = E+02\n",
        "# For example:\n",
        "# The first array of(x) is: ([[1.199920e+02, 1.573020e+02, 7.499700e+01, ..., 2.664820e-01,\n",
        "#        2.301442e+00, 2.846540e-01].  that is the first row.\n",
        "# The first row of (y) is :  1\n",
        "# Create the target data set\n",
        "\n",
        "yresult = np.array(df['status']) ## yresult this is going to be the 'x' here!, so yresult = y\n",
        "display (xprobe)\n",
        "# 10^2 = E+02  to understand the values that are inside the matrix of x matrix.\n",
        "display (yresult)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ 1.602340e+02,  2.903020e+02,  1.509970e+02,  9.840000e-03,\n",
              "         1.100000e-04,  1.370000e-02,  9.540000e-03,  6.109000e-02,\n",
              "         7.374000e-02,  8.260000e-01,  5.182000e-02,  6.130000e-02,\n",
              "         4.971000e-02,  1.054500e-01,  1.721100e-01,  2.103300e+01,\n",
              "         7.147830e-01,  8.463850e-01, -6.983031e+00,  3.884820e-01,\n",
              "         2.709662e+00,  2.945240e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ6nsJy6KX2-",
        "outputId": "54bd83c1-eb22-4558-d12b-0a822bca4a91"
      },
      "source": [
        "#### THIS IS GOING TO BE FOR INTRODUCE A NEW DATA AND PREDICT ####\n",
        "\n",
        "#Transform the data, the feature data values between 0 and 1 for x\n",
        "\n",
        "scla = MinMaxScaler(feature_range=(0,1))  #To understand what do MinMaxScaler uses this formula to create new values from the matrix of x_train or others:\n",
        "#  is this = X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
        "xprobe = scla.fit_transform(xprobe) #With fit.transform we trasform the data from the feature specified with sc from 0 to 1. #Which one is totally necessary due to the values\n",
        "# of the matrix are upper 100, 150, etc, so this help to have values among 0 to 1, that are more handable amounts.\n",
        "print(xprobe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fwyEhkWIxyK",
        "outputId": "61c64a13-8fac-40f4-d1a5-bdd2300c217e"
      },
      "source": [
        "#### THIS IS GOING TO BE FOR INTRODUCE A NEW DATA AND PREDICT ####\n",
        "\n",
        "predictions = model.predict(xprobe)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a1hUNa8SLD_"
      },
      "source": [
        "# Create a function for the models(3) to detect breast cancer\n",
        "# This is for train the data\n",
        "\n",
        "def models(x_train, y_train):\n",
        "\n",
        "# About the Logistic Regresion here is a very good video explanation: https://www.youtube.com/watch?v=yIYKR4sgzI8\n",
        "\n",
        "  #Logistic Regresion\n",
        "#  from sklearn.linear_model import LogisticRegression\n",
        "#  log = LogisticRegression(random_state=0)\n",
        "#  log.fit(x_train, y_train)    #This is for train this model\n",
        "\n",
        "# About Decision Tree is to chose from a top of a tree the principal or the root of the varibles that we have and is more reelevant fo the study it means\n",
        "# that if the values are important and we have a positive value of that has cancer so this variable among (radius_mean,\ttexture_mean,\tperimeter_mean,\tarea_mean\n",
        "# that are included in the x varible so this could be the root of it in this case the values that are higher such are related to to cancer because to more huge that\n",
        "# are the dimentions are highly provided evidence that there is cancer and we could have a positive breast cancer, that variables among the 29 using in the\n",
        "# main study is going to be the root of the tree. And from the root we chose the secuentiatly of the tree the second group important variable in base of the values of the\n",
        "# root... continuing doing it until to have the diagnosis if patient has or not the cancer.\n",
        "# For more information check this video of explanation: https://www.youtube.com/watch?v=7VeUPuFGJHk\n",
        "\n",
        "  #Decision Tree\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  tree = DecisionTreeClassifier(criterion = 'entropy', random_state=0)\n",
        "  tree.fit(x_train, y_train)  #This is for train this model\n",
        "\n",
        "\n",
        "  # Another model Random forest Classifier\n",
        "#  from sklearn.ensemble import RandomForestClassifier\n",
        "#  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "#  forest.fit(x_train, y_train) #This is for train this model\n",
        "\n",
        "  #Print the models accuracy on the train data\n",
        "#  print('[0] Logistic Regression Traininig Accuracy:', log.score (x_train, y_train))\n",
        "  print('[0] Logistic Regression Traininig Accuracy:', tree.score (x_train, y_train))\n",
        "#  print('[0] Logistic Regression Traininig Accuracy:', forest.score (x_train, y_train))\n",
        "\n",
        "  return tree #log, tree, forest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oK6psqtvCu1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24f0dYXjoUSs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "bf8092e8-d991-41e6-e4c5-6bc3f2b3bad7"
      },
      "source": [
        "#Print the prediction of the random forest classifier model\n",
        "pred = model.predict(y_test)\n",
        "pred\n",
        "\n",
        "#The fist array result is the prediction of the model of patients\n",
        "# that have or not cancer. And the second one array are the second array of\n",
        "# ptients that actuually has cancer it means  the real data.\n",
        "\n",
        "# To improve the accuracy of our Machine learning we could tweak(retocar)\n",
        "# some of the parameters and maybe even test other models as well better\n",
        "# And as we are dealing with human lives I want that to be as close as possible to 100%.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-9aee563d5fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Print the prediction of the random forest classifier model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#The fist array result is the prediction of the model of patients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \"\"\"\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0mtest_dmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_ntree_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[0;34m(self, mat, missing, nthread)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \"\"\"\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input numpy.ndarray must be 2 dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;31m# flatten the array by rows and ensure it is float32.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# we try to avoid data copies if possible (reshape returns a view when possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input numpy.ndarray must be 2 dimensional"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IcPHwZqVnM_"
      },
      "source": [
        "#Getting all of the models\n",
        "model = models(x_train, y_train)\n",
        "# x_train.shape\n",
        "# y_train.shape\n",
        "# print(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OpfB6BwgrKo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmgboxF4sQfE"
      },
      "source": [
        "#Show another way to get metrics of the models\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#  print( classification_report(y_test, model.predict(x_test)))\n",
        "#  print( accuracy_score(y_test, model.predict(x_test)))\n",
        "#  print()\n",
        "\n",
        "predictions = model.predict(y_test)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p8fp2T0Q2hO"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf_svm = svm.SVC(kernel='linear')\n",
        "\n",
        "clf_svm.fit(x_train, y_train)\n",
        "\n",
        "clf_svm.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klMZ6KGnXeGU"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "mod = LogisticRegression()\n",
        "mod.fit(x_train, y_train).predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OCaHciiiNYy"
      },
      "source": [
        "# Get the models accuracy, precision, recall and F1 score\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2nY7lB0aHg1"
      },
      "source": [
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "x_train, y_train = make_multilabel_classification(random_state=0)\n",
        "inner_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
        "clf = MultiOutputClassifier(inner_clf).fit(x_train, y_train)\n",
        "y_score = np.transpose([y_pred[:, 1] for y_pred in clf.predict_proba(x_train)])\n",
        "roc_auc_score(y_test, y_score, average=None)\n",
        "\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "clf = RidgeClassifierCV().fit(x_train, y_train)\n",
        "y_score = clf.decision_function(x_train)\n",
        "roc_auc_score(y_test, y_score, average=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piyzysb_1t3Z"
      },
      "source": [
        "# example of training a final classification model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_blobs\n",
        "# fit final model\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKKIhmKL1VP6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, predictions))\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "print(balanced_accuracy_score(y_test, predictions))\n",
        "from sklearn import svm; clf = svm.SVC(gamma=0.001, C=100.)\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdCABaSSC_Td"
      },
      "source": [
        "# example of training a final classification model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_blobs\n",
        "# fit final model\n",
        "model = LogisticRegression()\n",
        "model.fit(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcqkTpl_pMUr"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf_svm = svm.SVC(kernel='linear')\n",
        "\n",
        "clf_svm.fit(x_train, y_train)\n",
        "\n",
        "## x_test[0]\n",
        "\n",
        "## clf_svm.predict(x_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmiBuokJTVEN"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "mf = pd.read_csv('/content/drive/MyDrive/parkinsonsforpredict.csv')\n",
        "\n",
        "test_predict = best_model.predict(mf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP2rA14XEomF"
      },
      "source": [
        "mf = pd.read_csv('/content/drive/MyDrive/parkinsonsforpredict.csv')\n",
        "from sklearn import svm\n",
        "\n",
        "clf_svm = svm.SVC(kernel='linear')\n",
        "\n",
        "clf_svm.fit(x_train, y_train)\n",
        "\n",
        "clf_svm.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p94Jr-6CV499"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.svm import SVC\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "clf.set_params(kernel='linear').fit(test_x, test_y)\n",
        "SVC(kernel='linear')\n",
        "clf.predict(X[:5])\n",
        "array([0, 0, 0, 0, 0])\n",
        "\n",
        "clf.set_params(kernel='rbf').fit(X, y)\n",
        "SVC()\n",
        "clf.predict(X[:5])\n",
        "array([0, 0, 0, 0, 0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}